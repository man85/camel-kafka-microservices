version: '3.3'
services:

  zookeeper:
    image: confluentinc/cp-zookeeper:7.0.5
    hostname: zookeeper
    networks:
      - kafka_network
    ports:
      - 2181:2181
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181

  kafka:
    image: confluentinc/cp-kafka:7.0.5
    depends_on:
      - zookeeper
    hostname: kafka
    networks:
      - kafka_network
    ports:
      - 9092:9092
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "false"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1

  init-kafka:
    image: confluentinc/cp-kafka:7.0.5
    depends_on:
      - kafka
    networks:
      - kafka_network
    volumes:
      - ./logger-connector:/logger-connector
    entrypoint: [ '/bin/sh', '-c' ]
    command: |
      "
      # blocks until kafka is reachable
      kafka-topics --bootstrap-server kafka:9092 --list

      echo -e 'Creating kafka topics'
      kafka-topics --bootstrap-server kafka:9092 --create --if-not-exists \
          --topic consumer-topic \
          --partitions 6 \
          --replication-factor 1

      kafka-topics --bootstrap-server kafka:9092 --create --if-not-exists \
          --topic upper-case-text \
          --partitions 6 \
          --replication-factor 1

      echo -e 'Successfully created the following topics:'
      kafka-topics --bootstrap-server kafka:9092 --list
       sleep 20m
      "

#      read -p 'Press any key to resume ...'
#
#
#      echo -e 'Creating connector for logging a topic to a file'
#      connect-standalone /logger-connector/logger-connect-standalone.properties /logger-connector/logger-connect-file-sink.properties
#      "
#connect:
#  hostname: connect
#  image: jcustenborder/kafka-connect-all
#  depends_on:
#    - schema-registry
#    - kafka
#  ports:
#    - '8083:8083'
#  environment:
#    CONNECT_BOOTSTRAP_SERVERS: "kafka:9092"
##    CONNECT_REST_ADVERTISED_HOST_NAME: target-connect
##    CONNECT_PRODUCER_COMPRESSION_TYPE: lz4
#    CONNECT_GROUP_ID: connect
#    CONNECT_KEY_CONVERTER: io.confluent.connect.avro.AvroConverter
##    CONNECT_KEY_CONVERTER_SCHEMA_REGISTRY_URL: http://schema-registry:8081
#    CONNECT_VALUE_CONVERTER: io.confluent.connect.avro.AvroConverter
##    CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: http://schema-registry:8081
#    CONNECT_CONFIG_STORAGE_TOPIC: connect_config
#    CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 1
#    CONNECT_OFFSET_STORAGE_TOPIC: connect_offset
#    CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 1
#    CONNECT_STATUS_STORAGE_TOPIC: connect_status
#    CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 1
#    CONNECT_INTERNAL_KEY_CONVERTER: org.apache.kafka.connect.json.JsonConverter
#    CONNECT_INTERNAL_VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverter
#    CONNECT_INTERNAL_KEY_CONVERTER_SCHEMAS_ENABLE: 'false'
#    CONNECT_INTERNAL_VALUE_CONVERTER_SCHEMAS_ENABLE: 'false'
#    CONNECT_LOG4J_LOGGERS: 'org.reflections=ERROR'
#  volumes:
#    - './books.xsd:/books.xsd:ro'

  logger-connector:
    build: ./logger-connector/
#    build:
#      context: ./logger-connector/
#      dockerfile: Dockerfile
    container_name: logger-connector
    networks:
      - kafka_network
    depends_on:
      - kafka
      - init-kafka
    ports:
      - 8083:8083
    volumes:
      - ./tmp:/tmp
    links:
      - kafka


  http-receiver:
    build: ./http-receiver/
    image: http-receiver
    container_name: http-receiver
    networks:
      - kafka_network
    ports:
      - 8080:8080
    depends_on:
      - kafka
    links:
      - kafka

  processor:
    build: ./processor/
    image: processor
    container_name: processor
    networks:
      - kafka_network
    depends_on:
      - kafka
    links:
      - kafka

networks:
  kafka_network: